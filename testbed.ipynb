{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPUzx+xBl0eNTTKio230MhG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spencer-kanjera/Hybrid-Botnet-Detection-Using-GA-and-LightGBM/blob/main/testbed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzsyUIJ_HzyD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/Colab_files/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/Colab_files/foo.txt"
      ],
      "metadata": {
        "id": "-HjqFJC8IXb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer Dataset\n",
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "df['Target'] = cancer.target\n",
        "\n",
        "# Numeric and Boolean Data Type Mutations\n",
        "def mutate_numeric_column(value, mutation_rate=0.1):\n",
        "    if random.random() < mutation_rate:\n",
        "        operation = random.choice(['+', '-', '*', '/'])\n",
        "        mutation_value = random.uniform(0.5, 1.5)\n",
        "\n",
        "        if operation == '+':\n",
        "            return value + mutation_value\n",
        "        elif operation == '-':\n",
        "            return value - mutation_value\n",
        "        elif operation == '*':\n",
        "            return value * mutation_value\n",
        "        elif operation == '/':\n",
        "            if mutation_value != 0:\n",
        "                return value / mutation_value\n",
        "    return value\n",
        "\n",
        "def mutate_boolean_column(value, mutation_rate=0.1):\n",
        "    if random.random() < mutation_rate:\n",
        "        value = int(value)\n",
        "        mutation_value = random.randint(0, 1)\n",
        "        operation = random.choice(['AND', 'OR', 'XOR'])\n",
        "\n",
        "        if operation == 'AND':\n",
        "            return value & mutation_value\n",
        "        elif operation == 'OR':\n",
        "            return value | mutation_value\n",
        "        elif operation == 'XOR':\n",
        "            return value ^ mutation_value\n",
        "    return value\n",
        "\n",
        "def mutate_row(row, mutation_rate=0.1):\n",
        "    for col in row.index:\n",
        "        if col == 'Target':\n",
        "            row[col] = mutate_boolean_column(row[col], mutation_rate)\n",
        "        else:\n",
        "            row[col] = mutate_numeric_column(row[col], mutation_rate)\n",
        "    return row\n",
        "\n",
        "def create_new_row(df):\n",
        "    new_row = df.sample(n=1).copy().reset_index(drop=True).iloc[0]\n",
        "    new_row = mutate_row(new_row)\n",
        "    return new_row\n",
        "\n",
        "def evaluate_model_fitness(df):\n",
        "    X = df.drop(columns=['Target'])\n",
        "    y = df['Target']\n",
        "\n",
        "    # Split the data train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # LightGBM Dataset\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "    # Parameters\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_error',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': 31,\n",
        "        'learning_rate': 0.05,\n",
        "        'feature_fraction': 0.9,\n",
        "        'verbosity': -1  # Turn off the print statements of the function\n",
        "    }\n",
        "\n",
        "    # Train the model\n",
        "    model = lgb.train(params, train_data, num_boost_round=100, valid_sets=[test_data])\n",
        "\n",
        "    # Try it on test data\n",
        "    y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
        "    y_pred_test = [1 if pred > 0.5 else 0 for pred in y_pred_test]\n",
        "\n",
        "    # Accuracy Measurement\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    return test_accuracy\n",
        "\n",
        "def add_rows_to_df_with_fitness(df, num_rows=50):\n",
        "    fitness_scores = []\n",
        "    for _ in range(num_rows):\n",
        "        new_row = create_new_row(df)\n",
        "        temp_df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "        fitness_score = evaluate_model_fitness(temp_df)\n",
        "        fitness_scores.append((new_row, fitness_score))\n",
        "\n",
        "    # Sorting according to fitness scores\n",
        "    fitness_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Adding best fitness scores to data\n",
        "    best_rows = [row for row, score in fitness_scores[:num_rows//2]]\n",
        "    df = pd.concat([df, pd.DataFrame(best_rows)], ignore_index=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Extend the old data with new data\n",
        "df_expanded = add_rows_to_df_with_fitness(df, num_rows=1000)\n",
        "\n",
        "def evaluate_model(df, description=\"\"):\n",
        "    X = df.drop(columns=['Target'])\n",
        "    y = df['Target']\n",
        "\n",
        "    # Train test and validation\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    # LightGBM Dataset\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "    # Train Model\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_error',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': 31,\n",
        "        'learning_rate': 0.05,\n",
        "        'feature_fraction': 0.9,\n",
        "        'verbosity': -1\n",
        "    }\n",
        "\n",
        "    model = lgb.train(params, train_data, num_boost_round=100, valid_sets=[test_data])\n",
        "\n",
        "    # Predict on test and valdation dataset\n",
        "    y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
        "    y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "\n",
        "    y_pred_test = [1 if pred > 0.5 else 0 for pred in y_pred_test]\n",
        "    y_pred_val = [1 if pred > 0.5 else 0 for pred in y_pred_val]\n",
        "\n",
        "    # Accuracy measurement\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(f\"\\n{description} Data Set\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "    print(f\"Validation Set Accuracy: {val_accuracy:.2f}\")\n",
        "\n",
        "# Evaluate model with starting dataset\n",
        "evaluate_model(df, \"Start\")\n",
        "\n",
        "# Extended dataset evaluation\n",
        "evaluate_model(df_expanded, \"Extended\")"
      ],
      "metadata": {
        "id": "IAS53GVjKxLV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}