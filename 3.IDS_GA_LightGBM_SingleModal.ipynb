{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid Botnet Detection using GA and LightGBM - Single Modal\n",
    "\n",
    "1. **Import Required Packages**  \n",
    "   \n",
    "2. **Load and Prepare Datasets**  \n",
    "   - Load pre-split training and testing datasets from CSV files.  \n",
    "   - Inspect the data (check shapes, head, data types, etc.) to verify loading.\n",
    "\n",
    "3. **Preprocess Data**  \n",
    "   - **Remove Duplicates:** Eliminate redundant rows from both training and testing data.  \n",
    "   - **Handle Missing Values:**  \n",
    "     - Numeric columns: Fill with the column mean.  \n",
    "     - Non-numeric columns: Fill with the most frequent value (mode).  \n",
    "   - **Handle Infinite Values:** Replace any infinite values with NaN and then fill these using the column mean.  \n",
    "   - **Drop Single-value Columns:** Remove columns with only a single unique value.  \n",
    "   - **Clean Column Names:** Remove spaces to avoid issues in downstream processing.\n",
    "\n",
    "4. **Feature Engineering and Selection**  \n",
    "   - **Feature Selection:** Drop irrelevant columns so that the target variable (e.g., “attack”) is kept separate.  \n",
    "   - **Apply SMOTE:** Balance the class distribution in the training set using SMOTE.  \n",
    "   - **Scale Features:** Normalize the data using MinMaxScaler from scikit‑learn.  \n",
    "   - **Genetic Algorithm for Feature Selection:**  \n",
    "     - Use DEAP to set up a population of binary individuals (each represents a subset of features).  \n",
    "     - Evaluate candidates on a small subsample with a fast LightGBM model to approximate performance.  \n",
    "     - Run the GA for several generations, extract the best individual, and map the selected indices to actual feature names.\n",
    "\n",
    "5. **Train LightGBM Model**  \n",
    "   - **Cross-Validation and Performance Evaluation:**  \n",
    "     - Use 5‑fold Stratified Cross‑Validation on the training set with only the GA‑selected features.    \n",
    "     - Train the final LightGBM model using the selected features on the entire training set.  \n",
    "     - Evaluate the final model on the test set and print the performance metrics (all printed in full precision without rounding).\n",
    "\n",
    "6. **Evaluate Overfitting and Test on Unseen Data**  \n",
    "   - Compare the performance metrics between training and test sets to assess if the model is overfitting.  \n",
    "\n",
    "7. **Save Results and Final Model**  \n",
    "   - Persist the final trained LightGBM model to disk using Joblib for future use or deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the needed packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import multiprocessing\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2934817, 19)\n",
      "Testing data shape: (733705, 19)\n",
      "\n",
      "First 5 rows of Training Data:\n",
      "   pkSeqID proto            saddr  sport          daddr dport     seq  \\\n",
      "0  3142762   udp  192.168.100.150   6551  192.168.100.3    80  251984   \n",
      "1  2432264   tcp  192.168.100.150   5532  192.168.100.3    80  256724   \n",
      "2  1976315   tcp  192.168.100.147  27165  192.168.100.3    80   62921   \n",
      "3  1240757   udp  192.168.100.150  48719  192.168.100.3    80   99168   \n",
      "4  3257991   udp  192.168.100.147  22461  192.168.100.3    80  105063   \n",
      "\n",
      "     stddev  N_IN_Conn_P_SrcIP       min  state_number      mean  \\\n",
      "0  1.900363                100  0.000000             4  2.687519   \n",
      "1  0.078003                 38  3.856930             3  3.934927   \n",
      "2  0.268666                100  2.974100             3  3.341429   \n",
      "3  1.823185                 63  0.000000             4  3.222832   \n",
      "4  0.822418                100  2.979995             4  3.983222   \n",
      "\n",
      "   N_IN_Conn_P_DstIP  drate     srate       max  attack category subcategory  \n",
      "0                100    0.0  0.494549  4.031619       1     DDoS         UDP  \n",
      "1                100    0.0  0.256493  4.012924       1     DDoS         TCP  \n",
      "2                100    0.0  0.294880  3.609205       1     DDoS         TCP  \n",
      "3                 63    0.0  0.461435  4.942302       1      DoS         UDP  \n",
      "4                100    0.0  1.002999  4.994452       1     DDoS         UDP  \n",
      "\n",
      "First 5 rows of Testing Data:\n",
      "   pkSeqID proto            saddr  sport          daddr dport     seq  \\\n",
      "0   792371   udp  192.168.100.150  48516  192.168.100.3    80  175094   \n",
      "1  2056418   tcp  192.168.100.148  22267  192.168.100.3    80  143024   \n",
      "2  2795650   udp  192.168.100.149  28629  192.168.100.3    80  167033   \n",
      "3  2118009   tcp  192.168.100.148  42142  192.168.100.3    80  204615   \n",
      "4   303688   tcp  192.168.100.149   1645  192.168.100.5    80   40058   \n",
      "\n",
      "     stddev  N_IN_Conn_P_SrcIP       min  state_number      mean  \\\n",
      "0  0.226784                100  4.100436             4  4.457383   \n",
      "1  0.451998                100  3.439257             1  3.806172   \n",
      "2  1.931553                 73  0.000000             4  2.731204   \n",
      "3  0.428798                 56  3.271411             1  3.626428   \n",
      "4  2.058381                100  0.000000             3  1.188407   \n",
      "\n",
      "   N_IN_Conn_P_DstIP     drate     srate       max  attack category  \\\n",
      "0                100  0.000000  0.404711  4.719438       1      DoS   \n",
      "1                100  0.225077  0.401397  4.442930       1     DDoS   \n",
      "2                100  0.000000  0.407287  4.138455       1     DDoS   \n",
      "3                100  0.000000  0.343654  4.229700       1     DDoS   \n",
      "4                100  0.000000  0.135842  4.753628       1      DoS   \n",
      "\n",
      "  subcategory  \n",
      "0         UDP  \n",
      "1         TCP  \n",
      "2         UDP  \n",
      "3         TCP  \n",
      "4         TCP  \n",
      "\n",
      "Training Data Column Types:\n",
      "pkSeqID                int64\n",
      "proto                 object\n",
      "saddr                 object\n",
      "sport                 object\n",
      "daddr                 object\n",
      "dport                 object\n",
      "seq                    int64\n",
      "stddev               float64\n",
      "N_IN_Conn_P_SrcIP      int64\n",
      "min                  float64\n",
      "state_number           int64\n",
      "mean                 float64\n",
      "N_IN_Conn_P_DstIP      int64\n",
      "drate                float64\n",
      "srate                float64\n",
      "max                  float64\n",
      "attack                 int64\n",
      "category              object\n",
      "subcategory           object\n",
      "dtype: object\n",
      "\n",
      "Testing Data Column Types:\n",
      "pkSeqID                int64\n",
      "proto                 object\n",
      "saddr                 object\n",
      "sport                 object\n",
      "daddr                 object\n",
      "dport                 object\n",
      "seq                    int64\n",
      "stddev               float64\n",
      "N_IN_Conn_P_SrcIP      int64\n",
      "min                  float64\n",
      "state_number           int64\n",
      "mean                 float64\n",
      "N_IN_Conn_P_DstIP      int64\n",
      "drate                float64\n",
      "srate                float64\n",
      "max                  float64\n",
      "attack                 int64\n",
      "category              object\n",
      "subcategory           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Data Loading and Preprocessing\n",
    "# --------------------------------------\n",
    "# This cell loads the IoT Bot dataset, which is already split into training \n",
    "# and testing data. We load each CSV file from the specified paths, then print\n",
    "# key information such as the shape, the first few rows, and the data types \n",
    "# to verify that the data has been loaded correctly.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pre-split training data from the specified file path.\n",
    "data_train = pd.read_csv(r\"C:\\VS code projects\\data_files\\UNSW_2018_IoT_Botnet_Final_10_best_Training.csv\")\n",
    "# Load the pre-split testing data from the specified file path.\n",
    "data_test = pd.read_csv(r\"C:\\VS code projects\\data_files\\UNSW_2018_IoT_Botnet_Final_10_best_Testing.csv\")\n",
    "\n",
    "# Print the shape of the training and testing datasets.\n",
    "print(\"Training data shape:\", data_train.shape)\n",
    "print(\"Testing data shape:\", data_test.shape)\n",
    "\n",
    "# Display the first 5 rows of the training data to inspect the contents.\n",
    "print(\"\\nFirst 5 rows of Training Data:\")\n",
    "print(data_train.head())\n",
    "\n",
    "# Display the first 5 rows of the testing data.\n",
    "print(\"\\nFirst 5 rows of Testing Data:\")\n",
    "print(data_test.head())\n",
    "\n",
    "# Print the data types of each column in the training dataset for documentation.\n",
    "print(\"\\nTraining Data Column Types:\")\n",
    "print(data_train.dtypes)\n",
    "\n",
    "# Print the data types of each column in the testing dataset.\n",
    "print(\"\\nTesting Data Column Types:\")\n",
    "print(data_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after duplicates removed: (2934817, 19) (was (2934817, 19))\n",
      "Test shape after duplicates removed: (733705, 19) (was (733705, 19))\n",
      "Filled missing values in numeric columns.\n",
      "Filled missing values in non-numeric columns.\n",
      "Removed spaces from column names.\n",
      "Handled infinite values by replacing with NaN and filling with column means.\n",
      "Dropped 0 single-value columns from training data: []\n",
      "Dropped 0 single-value columns from testing data: []\n",
      "Final Train shape: (2934817, 19), Final Test shape: (733705, 19)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preprocessing - Cleaning and Preparation\n",
    "# ------------------------------------------------------\n",
    "# This cell cleans the training and testing datasets by:\n",
    "# 1. Removing duplicate rows.\n",
    "# 2. Filling missing values (numeric columns with means and non-numeric columns with modes).\n",
    "# 3. Removing extra spaces from column names.\n",
    "# 4. Handling infinite values by replacing them with NaN and then filling with means.\n",
    "# 5. Dropping columns that have only a single unique value (i.e., non-informative features).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Make copies of the input dataframes to ensure originals remain intact.\n",
    "data_train = data_train.copy()\n",
    "data_test = data_test.copy()\n",
    "\n",
    "# ------------------------------ #\n",
    "# 1. Remove duplicate rows\n",
    "# ------------------------------ #\n",
    "initial_train_shape = data_train.shape\n",
    "initial_test_shape = data_test.shape\n",
    "\n",
    "data_train.drop_duplicates(inplace=True)\n",
    "data_test.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Train shape after duplicates removed: {data_train.shape} (was {initial_train_shape})\")\n",
    "print(f\"Test shape after duplicates removed: {data_test.shape} (was {initial_test_shape})\")\n",
    "\n",
    "# ------------------------------ #\n",
    "# 2. Fill missing values for numeric columns\n",
    "# ------------------------------ #\n",
    "# Identify numeric columns from the data\n",
    "numeric_cols_train = data_train.select_dtypes(include=np.number).columns\n",
    "numeric_cols_test = data_test.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Fill missing values (NaN) in numeric columns with the column mean\n",
    "data_train[numeric_cols_train] = data_train[numeric_cols_train].fillna(data_train[numeric_cols_train].mean())\n",
    "data_test[numeric_cols_test] = data_test[numeric_cols_test].fillna(data_test[numeric_cols_test].mean())\n",
    "print(\"Filled missing values in numeric columns.\")\n",
    "\n",
    "# ------------------------------ #\n",
    "# 3. Fill missing values for non-numeric (categorical) columns\n",
    "# ------------------------------ #\n",
    "# Identify non-numeric columns from the data\n",
    "non_numeric_cols_train = data_train.select_dtypes(exclude=np.number).columns\n",
    "non_numeric_cols_test = data_test.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# For each non-numeric column, fill missing values with the most frequent (mode) value.\n",
    "for col in non_numeric_cols_train:\n",
    "    mode_val = data_train[col].mode()[0]\n",
    "    data_train[col] = data_train[col].fillna(mode_val)\n",
    "    \n",
    "for col in non_numeric_cols_test:\n",
    "    mode_val = data_test[col].mode()[0]\n",
    "    data_test[col] = data_test[col].fillna(mode_val)\n",
    "print(\"Filled missing values in non-numeric columns.\")\n",
    "\n",
    "# ------------------------------ #\n",
    "# 4. Remove spaces in column names\n",
    "# ------------------------------ #\n",
    "# This helps avoid issues when referencing columns later.\n",
    "data_train.columns = data_train.columns.str.replace(' ', '')\n",
    "data_test.columns = data_test.columns.str.replace(' ', '')\n",
    "print(\"Removed spaces from column names.\")\n",
    "\n",
    "# ------------------------------ #\n",
    "# 5. Handle infinite values in numeric columns\n",
    "# ------------------------------ #\n",
    "# Replace any positive or negative infinite values with NaN, and fill with mean\n",
    "data_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data_train[numeric_cols_train] = data_train[numeric_cols_train].fillna(data_train[numeric_cols_train].mean())\n",
    "data_test[numeric_cols_test] = data_test[numeric_cols_test].fillna(data_test[numeric_cols_test].mean())\n",
    "print(\"Handled infinite values by replacing with NaN and filling with column means.\")\n",
    "\n",
    "# ------------------------------ #\n",
    "# 6. Drop columns with a single unique value\n",
    "# ------------------------------ #\n",
    "# These columns do not provide any discriminative power for the model.\n",
    "cols_to_drop_train = [col for col in data_train.columns if data_train[col].nunique() == 1]\n",
    "cols_to_drop_test = [col for col in data_test.columns if data_test[col].nunique() == 1]\n",
    "data_train.drop(cols_to_drop_train, axis=1, inplace=True)\n",
    "data_test.drop(cols_to_drop_test, axis=1, inplace=True)\n",
    "\n",
    "print(f\"Dropped {len(cols_to_drop_train)} single-value columns from training data: {cols_to_drop_train}\")\n",
    "print(f\"Dropped {len(cols_to_drop_test)} single-value columns from testing data: {cols_to_drop_test}\")\n",
    "print(f\"Final Train shape: {data_train.shape}, Final Test shape: {data_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after feature selection: (2934817, 11)\n",
      "X_test shape after feature selection: (733705, 11)\n",
      "\n",
      "Unique classes in training target 'attack': [1 0]\n",
      "\n",
      "Distribution of target variable in training data:\n",
      "attack\n",
      "1    2934447\n",
      "0        370\n",
      "Name: count, dtype: int64\n",
      "Actual feature names: ['pkSeqID', 'seq', 'stddev', 'N_IN_Conn_P_SrcIP', 'min', 'state_number', 'mean', 'N_IN_Conn_P_DstIP', 'drate', 'srate', 'max']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Feature Selection\n",
    "# -------------------------\n",
    "# This cell selects the features for model training by removing columns that are either non-informative\n",
    "# or potentially problematic for the model. The 'attack' column (which is our target variable) is kept\n",
    "# separate to form y_train and y_test. We use errors='ignore' so that if any columns in our drop list\n",
    "# do not exist, the code will continue without error.\n",
    "#\n",
    "# After performing feature selection, we print the shapes of X_train and X_test to confirm the target number\n",
    "# of features, and we also output some information about the target variable.\n",
    "\n",
    "# Define the list of columns to drop.\n",
    "columns_to_drop = [\n",
    "    'category', 'subcategory', 'proto', 'saddr', 'sport', 'daddr', 'dport', 'attack',\n",
    "    'starttime', 'ltime', 'sid', 'sessionid', 'tcprtt', 'synack', 'ackdat', 'state',\n",
    "    'service', 'smac', 'dmac', 'trans_depth', 'response_body_len'\n",
    "]\n",
    "\n",
    "# For the training data:\n",
    "# Remove the specified columns from the features.\n",
    "X_train = data_train.drop(columns=columns_to_drop, axis=1, errors='ignore')\n",
    "# Extract the 'attack' column as the target.\n",
    "y_train = data_train['attack']\n",
    "\n",
    "# For the testing data, repeat the process.\n",
    "X_test = data_test.drop(columns=columns_to_drop, axis=1, errors='ignore')\n",
    "y_test = data_test['attack']\n",
    "\n",
    "# Print out the resulting shapes and target variable info to ensure correctness.\n",
    "print(\"X_train shape after feature selection:\", X_train.shape)\n",
    "print(\"X_test shape after feature selection:\", X_test.shape)\n",
    "print(\"\\nUnique classes in training target 'attack':\", y_train.unique())\n",
    "print(\"\\nDistribution of target variable in training data:\")\n",
    "print(y_train.value_counts())\n",
    "X_train_orig = data_train.drop(columns=columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# Now extract the actual feature names:\n",
    "feature_names = X_train_orig.columns.tolist()\n",
    "\n",
    "# Optionally print them to verify:\n",
    "print(\"Actual feature names:\", feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after SMOTE: (5868894, 11) (5868894,)\n",
      "Shape after subsampling SMOTE data: (2934447, 11) (2934447,)\n",
      "Target distribution after SMOTE and subsampling:\n",
      "attack\n",
      "0    1467673\n",
      "1    1466774\n",
      "Name: count, dtype: int64\n",
      "X_train_scaled shape: (2934447, 11)\n",
      "X_test_scaled shape: (733705, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Apply SMOTE for Balancing\n",
    "# -------------------------------\n",
    "# Assuming X_train and y_train have been defined in previous steps.\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"Shape after SMOTE:\", X_train_resampled.shape, np.array(y_train_resampled).shape)\n",
    "\n",
    "# Ensure the outputs are in DataFrame/Series format\n",
    "if not isinstance(X_train_resampled, pd.DataFrame):\n",
    "    X_train_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "if not isinstance(y_train_resampled, pd.Series):\n",
    "    y_train_resampled = pd.Series(y_train_resampled)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Subsample the SMOTE Data\n",
    "# -------------------------------\n",
    "# Retain 50% of the SMOTE-generated samples\n",
    "sample_fraction = 0.5\n",
    "n_samples = int(X_train_resampled.shape[0] * sample_fraction)\n",
    "selected_indices = np.random.choice(X_train_resampled.shape[0], size=n_samples, replace=False)\n",
    "\n",
    "# Subsample both features and target labels\n",
    "X_train_balanced = X_train_resampled.iloc[selected_indices]\n",
    "y_train_balanced = y_train_resampled.iloc[selected_indices]\n",
    "\n",
    "print(\"Shape after subsampling SMOTE data:\", X_train_balanced.shape, y_train_balanced.shape)\n",
    "print(\"Target distribution after SMOTE and subsampling:\")\n",
    "print(y_train_balanced.value_counts())\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Scale the Features\n",
    "# -------------------------------\n",
    "# Fit the scaler on the balanced training data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "# Scale the test set (ensure X_test has gone through the same preprocessing as X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# Update Global Variables for Consistency\n",
    "# -------------------------------\n",
    "# To ensure that the Genetic Algorithm evaluations use the balanced and scaled data,\n",
    "# update y_train to be the balanced version.\n",
    "y_train = y_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 in progress...\n",
      "Generation 1 completed. Max Fitness: 1.0 , Avg Fitness: 0.946526820348647\n",
      "Generation 2 in progress...\n",
      "Generation 2 completed. Max Fitness: 1.0 , Avg Fitness: 0.9966468965664967\n",
      "Generation 3 in progress...\n",
      "Generation 3 completed. Max Fitness: 1.0 , Avg Fitness: 0.9997284227929149\n",
      "Generation 4 in progress...\n",
      "Generation 4 completed. Max Fitness: 1.0 , Avg Fitness: 0.9927986399962613\n",
      "Generation 5 in progress...\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Suppress warnings and LightGBM logs\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Predefined Data\n",
    "# ---------------------------------------------------------------------------\n",
    "# Assumptions:\n",
    "# - X_train_scaled: NumPy array of scaled training features (shape: n_samples, n_features)\n",
    "# - y_train: Training labels (pandas Series or NumPy array)\n",
    "# - feature_names: List of original feature names from your training DataFrame\n",
    "\n",
    "if 'feature_names' not in globals():\n",
    "    feature_names = X_train.columns.tolist()\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate': 0.01990086265614642,\n",
    "    'num_leaves': 65,\n",
    "    'max_depth': 7,\n",
    "    'min_child_samples': 40,\n",
    "    'subsample': 0.6971404971190901,\n",
    "    'colsample_bytree': 0.8912957047621014,\n",
    "    'reg_alpha': 0.00001077475757773147,\n",
    "    'reg_lambda': 7.505137036788418,\n",
    "    'n_estimators': 386,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "eval_fraction = 0.7  # Use 70% of the training data for evaluation for better stability\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# GA Setup Using DEAP\n",
    "# ---------------------------------------------------------------------------\n",
    "# Clear any previous creator definitions (useful in interactive environments)\n",
    "for name in [\"FitnessMax\", \"Individual\"]:\n",
    "    if hasattr(creator, name):\n",
    "        delattr(creator, name)\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "num_features = X_train_scaled.shape[1]\n",
    "\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# GA Hyperparameters (tuned for better exploration)\n",
    "population_size = 20         # Increased population size for better diversity\n",
    "n_generations = 10           # Number of GA generations\n",
    "crossover_prob = 0.8         # Higher crossover probability\n",
    "mutation_prob = 0.3          # Higher mutation probability\n",
    "mutation_indpb = 0.08        # Per-bit mutation probability\n",
    "\n",
    "# Adjust minimum features threshold based on the total number of features.\n",
    "# Previously, using max(10, int(0.2 * num_features)) could force a minimum that's too high.\n",
    "# We now use: at least 20% of the features *or* 1 (if 20% is less than 1), whichever is higher.\n",
    "min_features = max(1, int(0.2 * num_features))\n",
    "\n",
    "# Cache to avoid duplicate evaluations\n",
    "fitness_cache = {}\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Evaluation Function\n",
    "# ---------------------------------------------------------------------------\n",
    "def evaluate_individual(individual, min_features, eval_fraction):\n",
    "    \"\"\"\n",
    "    Evaluate an individual by selecting features (based on the binary mask)\n",
    "    and training a simplified LightGBM model on a random subset of the training data.\n",
    "    Returns the accuracy as the fitness value.\n",
    "    \"\"\"\n",
    "    key = tuple(individual)\n",
    "    if key in fitness_cache:\n",
    "        return fitness_cache[key]\n",
    "    \n",
    "    # Get indices of selected features\n",
    "    selected = [i for i, bit in enumerate(individual) if bit]\n",
    "    # If fewer than the minimum required features are selected, assign 0 fitness.\n",
    "    if len(selected) < min_features:\n",
    "        fitness_cache[key] = (0.0,)\n",
    "        return (0.0,)\n",
    "    \n",
    "    # Randomly sample a subset of the training data\n",
    "    num_samples = len(y_train)\n",
    "    n_samples = int(num_samples * eval_fraction)\n",
    "    indices = np.random.choice(num_samples, size=n_samples, replace=False)\n",
    "    \n",
    "    # Subsample X and y\n",
    "    X_sub = X_train_scaled[indices][:, selected]\n",
    "    y_sub = np.array(y_train)[indices]\n",
    "    \n",
    "    # Configure a lighter LightGBM model for evaluation purposes\n",
    "    fast_params = lgb_params.copy()\n",
    "    fast_params['n_estimators'] = 50  # More than 20, but still fast\n",
    "    fast_params['max_depth'] = 6      # Slightly deeper for a richer evaluation\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**fast_params)\n",
    "    model.fit(X_sub, y_sub)\n",
    "    y_pred = model.predict(X_sub)\n",
    "    \n",
    "    # Calculate accuracy as the fitness metric (consider alternative metrics if needed)\n",
    "    acc = accuracy_score(y_sub, y_pred)\n",
    "    fitness_cache[key] = (acc,)\n",
    "    return (acc,)\n",
    "\n",
    "# Register evaluation and genetic operations\n",
    "toolbox.register(\"evaluate\", evaluate_individual, min_features=min_features, eval_fraction=eval_fraction)\n",
    "toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=mutation_indpb)\n",
    "toolbox.register(\"select\", tools.selRandom)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Run GA Evolution\n",
    "# ---------------------------------------------------------------------------\n",
    "population = toolbox.population(n=population_size)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = [\"gen\", \"avg\", \"max\"]\n",
    "\n",
    "for gen in range(n_generations):\n",
    "    print(f\"Generation {gen + 1} in progress...\")\n",
    "    population, logbook = algorithms.eaSimple(\n",
    "        population, toolbox, \n",
    "        cxpb=crossover_prob, mutpb=mutation_prob, ngen=1, \n",
    "        stats=stats, verbose=False\n",
    "    )\n",
    "    record = logbook[-1]\n",
    "    print(f\"Generation {gen + 1} completed. Max Fitness: {record['max']} , Avg Fitness: {record['avg']}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Extract and Print Best Individual\n",
    "# ---------------------------------------------------------------------------\n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "selected_feature_indices = [i for i, bit in enumerate(best_individual) if bit]\n",
    "chosen_features = [feature_names[i] for i in selected_feature_indices]\n",
    "\n",
    "print(f\"\\nNumber of selected features: {len(chosen_features)}\")\n",
    "print(\"Selected Features (by name):\")\n",
    "for idx, feature in enumerate(chosen_features, start=1):\n",
    "    print(f\"{idx}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM with 5-Fold Stratified Cross-Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1 of 5...\n",
      "Fold 1 Results:\n",
      "  Accuracy:  0.4996063998364259\n",
      "  Precision: 0.49934289857259817\n",
      "  Recall:    0.4996063998364259\n",
      "  F1 Score:  0.44510341868893516\n",
      "  Confusion Matrix:\n",
      "[[238576  54874]\n",
      " [238802  54638]]\n",
      "\n",
      "Training Fold 2 of 5...\n",
      "Fold 2 Results:\n",
      "  Accuracy:  0.49948371926596125\n",
      "  Precision: 0.499481398291053\n",
      "  Recall:    0.49948371926596125\n",
      "  F1 Score:  0.49904484991724934\n",
      "  Confusion Matrix:\n",
      "[[155259 138191]\n",
      " [155557 137883]]\n",
      "\n",
      "Training Fold 3 of 5...\n",
      "Fold 3 Results:\n",
      "  Accuracy:  0.5007693107214481\n",
      "  Precision: 0.5008123828401254\n",
      "  Recall:    0.5007693107214481\n",
      "  F1 Score:  0.4937782381945214\n",
      "  Confusion Matrix:\n",
      "[[181435 112014]\n",
      " [180979 112461]]\n",
      "\n",
      "Training Fold 4 of 5...\n",
      "Fold 4 Results:\n",
      "  Accuracy:  0.4994658274392602\n",
      "  Precision: 0.49943547288960594\n",
      "  Recall:    0.4994658274392602\n",
      "  F1 Score:  0.49312224739172306\n",
      "  Confusion Matrix:\n",
      "[[179396 114054]\n",
      " [179704 113735]]\n",
      "\n",
      "Training Fold 5 of 5...\n",
      "Fold 5 Results:\n",
      "  Accuracy:  0.49907904220389204\n",
      "  Precision: 0.4990750759545955\n",
      "  Recall:    0.49907904220389204\n",
      "  F1 Score:  0.49845163333135034\n",
      "  Confusion Matrix:\n",
      "[[136076 157374]\n",
      " [136611 156828]]\n",
      "\n",
      "Average Metrics Across All Folds:\n",
      "  Accuracy: 0.4996808598933975\n",
      "  Precision: 0.49962944570959567\n",
      "  Recall: 0.4996808598933975\n",
      "  F1 Score: 0.48590007750475583\n",
      "  Average Confusion Matrix:\n",
      "[[178148.4 115301.4]\n",
      " [178330.6 115109. ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training LightGBM with 5-Fold Stratified Cross-Validation\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Prepare Data with Selected Features\n",
    "# ---------------------------------------------------------------------------\n",
    "# Use only the GA-selected features for training and testing\n",
    "X_selected = X_train_scaled[:, selected_feature_indices]\n",
    "X_test_selected = X_test_scaled[:, selected_feature_indices]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Set Up 5-Fold Stratified Cross-Validation\n",
    "# ---------------------------------------------------------------------------\n",
    "# StratifiedKFold ensures that each fold preserves the class distribution\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store the performance metrics of each fold\n",
    "fold_results = []\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_selected, y_train), 1):\n",
    "    print(f\"\\nTraining Fold {fold} of 5...\")\n",
    "\n",
    "    # Create training and validation datasets for the current fold\n",
    "    X_train_fold = X_selected[train_idx]\n",
    "    X_val_fold = X_selected[val_idx]\n",
    "    y_train_fold = y_train.iloc[train_idx] if hasattr(y_train, \"iloc\") else y_train[train_idx]\n",
    "    y_val_fold = y_train.iloc[val_idx] if hasattr(y_train, \"iloc\") else y_train[val_idx]\n",
    "\n",
    "    # Train the LightGBM model on the training set of this fold\n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        eval_set=[(X_val_fold, y_val_fold)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]\n",
    "    )\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Calculate fold-specific metrics\n",
    "    fold_accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    fold_precision = precision_score(y_val_fold, y_pred, average='weighted')\n",
    "    fold_recall = recall_score(y_val_fold, y_pred, average='weighted')\n",
    "    fold_f1 = f1_score(y_val_fold, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "\n",
    "    # Store the metrics for this fold\n",
    "    fold_results.append({\n",
    "        \"Fold\": fold,\n",
    "        \"Accuracy\": fold_accuracy,\n",
    "        \"Precision\": fold_precision,\n",
    "        \"Recall\": fold_recall,\n",
    "        \"F1 Score\": fold_f1,\n",
    "        \"Confusion Matrix\": cm\n",
    "    })\n",
    "\n",
    "    # Print fold-specific metrics\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(\"  Accuracy: \", fold_accuracy)\n",
    "    print(\"  Precision:\", fold_precision)\n",
    "    print(\"  Recall:   \", fold_recall)\n",
    "    print(\"  F1 Score: \", fold_f1)\n",
    "    print(\"  Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Compute and Print Average Metrics Across All Folds\n",
    "# ---------------------------------------------------------------------------\n",
    "# Aggregate metrics across all folds\n",
    "avg_accuracy = np.mean([result[\"Accuracy\"] for result in fold_results])\n",
    "avg_precision = np.mean([result[\"Precision\"] for result in fold_results])\n",
    "avg_recall = np.mean([result[\"Recall\"] for result in fold_results])\n",
    "avg_f1 = np.mean([result[\"F1 Score\"] for result in fold_results])\n",
    "avg_cm = np.mean(np.array([result[\"Confusion Matrix\"] for result in fold_results]), axis=0)\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across All Folds:\")\n",
    "print(\"  Accuracy:\", avg_accuracy)\n",
    "print(\"  Precision:\", avg_precision)\n",
    "print(\"  Recall:\", avg_recall)\n",
    "print(\"  F1 Score:\", avg_f1)\n",
    "print(\"  Average Confusion Matrix:\")\n",
    "print(avg_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m final_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlgb_params)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train the final model on the entire training set using only the selected features.\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save the final trained model to a file for later use (e.g., during deployment or further evaluation).\u001b[39;00m\n\u001b[0;32m     21\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(final_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_lightgbm_model.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Spencer Kanjera\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1284\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Spencer Kanjera\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[1;32mc:\\Users\\Spencer Kanjera\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Spencer Kanjera\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4135\u001b[0m _safe_call(\n\u001b[1;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4140\u001b[0m )\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Train and Save the Final LightGBM Model\n",
    "# ---------------------------------------------------------------------------\n",
    "# This cell trains the final LightGBM model using all the training data,\n",
    "# but only with the features that were selected by the GA.\n",
    "#\n",
    "# Variables assumed to be available in the environment:\n",
    "#   - X_selected: A NumPy array containing training features corresponding to the selected feature indices.\n",
    "#   - y_train: Training labels (can be a pandas Series or NumPy array).\n",
    "#   - lgb_params: Dictionary of LightGBM hyperparameters defined earlier in the pipeline.\n",
    "#\n",
    "# After training, the model is saved to disk using Joblib.\n",
    "\n",
    "# Initialize the LightGBM classifier with the predefined parameters.\n",
    "final_model = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "# Train the final model on the entire training set using only the selected features.\n",
    "final_model.fit(X_selected, y_train)\n",
    "\n",
    "# Save the final trained model to a file for later use (e.g., during deployment or further evaluation).\n",
    "joblib.dump(final_model, \"final_lightgbm_model.joblib\")\n",
    "print(\"Final LightGBM model saved as 'final_lightgbm_model.joblib'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for Overfitting: Comparing Training and Test Performance\n",
      "\n",
      "Training Metrics (Full Precision):\n",
      "  Accuracy: 0.5138954630974762\n",
      "  Precision: 0.5139178608795921\n",
      "  Recall: 0.5138954630974762\n",
      "  F1 Score: 0.5136373991152239\n",
      "  Confusion Matrix:\n",
      "[[719979 746799]\n",
      " [679649 788020]]\n",
      "\n",
      "Test Metrics (Full Precision):\n",
      "  Accuracy: 0.5230235585146619\n",
      "  Precision: 0.9997134893497115\n",
      "  Recall: 0.523023558514662\n",
      "  F1 Score: 0.6866928517606816\n",
      "  Confusion Matrix:\n",
      "[[    53     54]\n",
      " [349906 383692]]\n",
      "\n",
      "Overfitting Assessment:\n",
      "  Difference in Accuracy (Training - Test): -0.009128095417185622\n",
      "  Training Accuracy: 0.5138954630974762\n",
      "  Test Accuracy: 0.5230235585146619\n",
      "The model generalizes well. Training and test metrics are comparable, indicating minimal overfitting.\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing for Overfitting: Comparing Training and Test Performance\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Evaluate Performance on the Training Set\n",
    "# ---------------------------------------------------------------------------\n",
    "# Get predictions on the training set using the final model.\n",
    "y_pred_train = final_model.predict(X_selected)\n",
    "\n",
    "# Calculate performance metrics on the training set (using full precision).\n",
    "train_accuracy  = accuracy_score(y_train, y_pred_train)\n",
    "train_precision = precision_score(y_train, y_pred_train, average='weighted')\n",
    "train_recall    = recall_score(y_train, y_pred_train, average='weighted')\n",
    "train_f1        = f1_score(y_train, y_pred_train, average='weighted')\n",
    "train_cm        = confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTraining Metrics (Full Precision):\")\n",
    "print(\"  Accuracy:\", train_accuracy)\n",
    "print(\"  Precision:\", train_precision)\n",
    "print(\"  Recall:\", train_recall)\n",
    "print(\"  F1 Score:\", train_f1)\n",
    "print(\"  Confusion Matrix:\")\n",
    "print(train_cm)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Evaluate Performance on the Test Set\n",
    "# ---------------------------------------------------------------------------\n",
    "# Get predictions on the test set.\n",
    "y_pred_test = final_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate performance metrics on the test set (using full precision).\n",
    "test_accuracy  = accuracy_score(y_test, y_pred_test)\n",
    "test_precision = precision_score(y_test, y_pred_test, average='weighted')\n",
    "test_recall    = recall_score(y_test, y_pred_test, average='weighted')\n",
    "test_f1        = f1_score(y_test, y_pred_test, average='weighted')\n",
    "test_cm        = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nTest Metrics (Full Precision):\")\n",
    "print(\"  Accuracy:\", test_accuracy)\n",
    "print(\"  Precision:\", test_precision)\n",
    "print(\"  Recall:\", test_recall)\n",
    "print(\"  F1 Score:\", test_f1)\n",
    "print(\"  Confusion Matrix:\")\n",
    "print(test_cm)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Overfitting Check\n",
    "# ---------------------------------------------------------------------------\n",
    "# A significant drop in performance from training to test can indicate overfitting.\n",
    "print(\"\\nOverfitting Assessment:\")\n",
    "\n",
    "# Here we simply compare training and test metrics.\n",
    "# You may adjust the threshold (e.g. 1% drop) based on domain requirements.\n",
    "accuracy_drop = train_accuracy - test_accuracy\n",
    "\n",
    "print(\"  Difference in Accuracy (Training - Test):\", accuracy_drop)\n",
    "print(\"  Training Accuracy:\", train_accuracy)\n",
    "print(\"  Test Accuracy:\", test_accuracy)\n",
    "\n",
    "if accuracy_drop > 0.01:\n",
    "    print(\"Warning: The model may be overfitting because there is a significant drop in accuracy from training to test.\")\n",
    "else:\n",
    "    print(\"The model generalizes well. Training and test metrics are comparable, indicating minimal overfitting.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
